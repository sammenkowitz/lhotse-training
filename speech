# Shalom World

import lhotse, os, gzip, shutil
from lhotse import CutSet, Mfcc, Fbank
import lhotse.recipes
from lhotse.audio import Recording, RecordingSet
from lhotse.recipes.utils import manifests_exist, read_manifests_if_cached
from lhotse.supervision import AlignmentItem, SupervisionSegment, SupervisionSet

from tqdm.auto import tqdm
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple, Union

Pathlike = Union[Path, str]

def prepare_corpora(root_dir, out_dir = None):
    
    if out_dir == None:
        out_dir = root_dir # root_dir = out_dir = ...\train; \train\audio\0001... and \train\annotation\0001...
                           # -> \train\recording\0001... and \train\supervision\0001...    
    root_dir = Path(root_dir)
    out_dir = Path(out_dir)
    assert root_dir.is_dir(), f"No such directory: {root_dir}"
    assert out_dir.is_dir(), f"No such directory: {out_dir}"
    
    stems = [] # stems replace {dataset_parts} by keeping .stem of audio, annotation
    for filename in os.listdir(os.path.join(root_dir, 'annotation')):
        f = Path(filename).stem.split('_')
        stems.append(f[1])
        
    if not Path(os.path.join(out_dir,'supervison')).is_dir():
        os.mkdir(os.path.join(out_dir,'supervison'))
    if not Path(os.path.join(out_dir,'recording')).is_dir():
        os.mkdir(os.path.join(out_dir,'recording'))
        
    for stem in stems:
        
        annotationdir = os.path.join(root_dir,f"annotation\\fla_{stem}.txt")
        audiodir = os.path.join(root_dir,f"audio\\fla_{stem}.wav")        
        supervisiondir = os.path.join(out_dir,f"supervison\\super_{stem}.jsonl")
        recordingdir = os.path.join(out_dir,f"recording\\rec_{stem}.jsonl")
        
        with open(annotationdir, 'r', encoding='utf-8') as annotation_data:

            with open(supervisiondir, 'w', encoding='utf-8') as prime_manifest:
                with open(recordingdir, 'w') as vice_manifest:
                    sub = 0

                    audiodir = Path(audiodir)
                    recording_id = audiodir.stem
                    # audio_info = info(audiodir)

                    for line in annotation_data.read().split('\n'):
                        if line != '':
                            line = line.split('\t')
                            line[0] = line[0].split(' ')

                            supervision = {}
                            supervision['id'] = Path(annotationdir).stem + f"-cut_{sub}"
                            supervision['recording_id'] = Path(audiodir).stem
                            supervision['start'] = float(line[0][0])
                            supervision['duration'] = round(float(line[0][1]) - float(line[0][0]), 3)
                            supervision['channel'] = 0
                            supervision['text'] = line[1]
                            supervision['text_english'] = line[2]
                            supervision['language'] = 'Arabic'
                            supervision['speaker'] = line[0][2]
                            prime_manifest.write(str(supervision))

                            recording = {}
                            recording['id'] = recording_id
                            recording['sources'] = {}
                            recording['sources']['type'] = 'file'
                            recording['sources']['channels'] = [0]
                            recording['sources']['source'] = str(audiodir)
                            recording['sampling_rate'] = None
                            recording['num_samples'] = None
                            recording['duration'] = round(float(line[0][1]) - float(line[0][0]), 3)
                            vice_manifest.write(str(recording))

                            sub += 1
